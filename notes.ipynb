{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emergence of Compositional Language in a multi-agent environment based on Spatio-Temporal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Introduction:__\n",
    "In this work we are going to show that neural agents can develop a compositional language by capturing both spatial and temporal features in their environment. In natural languages, humans usually describe actions or a state of being by means of verbs. A verb in syntax may refer to a phenomenon with certain spatio-temporal features distinguishable by humans, but how are those words picked to refer to the right thing or action? How could an intelligent system map the right word to the right meaning? To this date, these are one of the greatest challenges in AI.\n",
    "\n",
    "Some suggest that for a computer to pick the right referent, it may need the capacity to explore its world in order to categorize and act upon the meanings that those words are connected to. Like any other object or abstract concept, actions and processes also need to be grounded so that they could be associated with the right symbol through an internal mechanism when needed. As an example, [studies](https://www.researchgate.net/publication/224855663_Discrimination_and_Categorization_of_Actions_by_Pigeons) show that pigeons can discriminate actions and behaviors by recognizing the sequence of different poses across time. This cognitive ability could help animals to take the right action when facing different situations.\n",
    "\n",
    "<center><img src=\"fig_1.png\"></center>\n",
    "\n",
    "In this work, we aim to design a multi-agent environment in which agents can learn to communicate with each other and ground not only the meaning behind the objects but also the actions in question by playing a language game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Literature Review:__\n",
    "There has been a number of notable studies carried out on this topic. Cangelosi and Parisi ([1998](http://www.people.ku.edu/~mvitevit/CangelosiParisi.pdf)) developed a model that neural agents evolve a communication system to categorize objects by receiving and producing signals from each other under an indirect evolutionary pressure. On the other hand, Batali ([1998](https://www.researchgate.net/publication/243766191_Computational_simulations_of_the_emergence_of_grammar)) used the obverter technique with which neural agents produce a sequence of discrete symbols that maximize their own understanding of the phenomenon before passing it to the other agents. In the recent years, with the advancement of new techniques and methods in artificial intelligence new experiments have been designed in which a language or communication system emerge in different scenarios that agents play language games (Lazaridou et al [2017](https://arxiv.org/abs/1612.07182), Mordatch and Abbeel [2017](https://arxiv.org/abs/1703.04908), Chabouni et al [2021](https://www.pnas.org/content/118/12/e2016569118), Dagan et al [2020](https://arxiv.org/abs/2001.03361), Cao and Lazaridou [2018](https://arxiv.org/abs/1804.03980)).\n",
    "\n",
    "Choi and Lazaridou ([2018](https://arxiv.org/abs/1804.02341)) used Batali's obverter technique to come  up with a model whose agents can learn a compositional language out of raw image pixels without any explicit supervision. Inspired by Choi and Lazaridou's work, we also would like to design an environment whose agents can ground actions by capturing the temporal and spatial features of events instead of raw static images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Method:__\n",
    "#### __The language game:__\n",
    "In order for a language emerge, similar to other works mentioned before, we let the neural agents play a communication game. In each round of this game, agents can take 2 different roles either as a speaker or a listener. An event is shown to the speaker agent and it's asked to describe the event with a sequence of tokens or symbols that maximizes its understanding of that event by iterating over different symbols. On the other hand, the listener is shown another event which can be either of the same type or of a different event. (note that the event can be similar but not identical). The listener also takes the input from the speaker and should decide whether it sees the same type of event or not. In the hypothetical scenario that we have designed, two agents should communicate with each other to distinguish between different types of preys (poisonous and edible) with different behaviors (spinning, moving, staying still) by playing the aforementioned game (note that the events shown are in GIF format and are static in the following figure).\n",
    "\n",
    "<center><img src=\"fig_2.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Events:__\n",
    "The events shown to the agents are randomly generated by drawing voronoi cells around a random population of points. The poisonous organisms have a denser population of cells than the edible ones and both types are capable of doing three actions. Let's generate some sample events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organism 1 generated\n",
      "Organism 2 generated\n",
      "Organism 3 generated\n"
     ]
    }
   ],
   "source": [
    "from organisms import OrganismGenerator\n",
    "\n",
    "mother = OrganismGenerator(path='./examples/')\n",
    "mother.min_cell_no = 20\n",
    "mother.max_cell_no = 200\n",
    "mother.noise = True\n",
    "\n",
    "# generate an edible organism  being still\n",
    "mother.draw(1, org_type='edible', movement='still', dpi=20)\n",
    "# generate an edible organism  spinning\n",
    "mother.draw(2, org_type='edible', movement='spin', dpi=20)\n",
    "# generate an edible organism  moving\n",
    "mother.draw(3, org_type='edible', movement='move', dpi=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see the generated edible examples:\n",
    "\n",
    "<center><img src=\"./examples/000001_still_edible.gif\" width=\"128\"/> <img src=\"./examples/000002_spin_edible.gif\" width=\"128\"/><img src=\"./examples/000003_move_edible.gif\" width=\"128\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organism 4 generated\n",
      "Organism 5 generated\n",
      "Organism 6 generated\n"
     ]
    }
   ],
   "source": [
    "# generate an poisonous organism  being still\n",
    "mother.draw(4, org_type='poisonous', movement='still', dpi=20)\n",
    "# generate an poisonous organism  spinning\n",
    "mother.draw(5, org_type='poisonous', movement='spin', dpi=20)\n",
    "# generate an poisonous organism  moving\n",
    "mother.draw(6, org_type='poisonous', movement='move', dpi=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see the generated poisonous examples:\n",
    "\n",
    "<center><img src=\"./examples/000004_still_poisonous.gif\" width=\"128\"/> <img src=\"./examples/000005_spin_poisonous.gif\" width=\"128\"/><img src=\"./examples/000006_move_poisonous.gif\" width=\"128\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, around 5000 organisms are generated sampled from a uniform distribution of 6 categories (1/6). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Agents Architecture:__\n",
    "We are currently working on two different architectures. In the first proposed model, the architecture of each agent is composed of 3 main modules (visual, lingual and reasoning modules). Each frame of an event is forward passed through a pre-trained convolutional neural network to encode them as vectors. The vectors are stacked on top of each other to represent a single event and then are passed through a Seq2Seq network to be encoded as a single vector capturing the temporal features. The lingual module on the other hand is a Recurrent Neural network responsible for digesting and generating sequence of symbols. The reasoning module is a multilayer perceptron on top of the visual and language modules which decides whether the event and the symbols received are of the same type or not. The visual module of the model is inspired by the work of Venugopalan et al [2015](https://arxiv.org/abs/1505.00487) who have implemented a sequence to sequence model to caption videos and for the same reason we also call our model Seq2Seq agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"fig_3.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model's visual module is inspired by work of Simonyan and Zisserman [2014](https://arxiv.org/abs/1406.2199) and because of this its architecture is called two-stream. In order to recognize the actions in videos, they used two-stream covelutional networks, one stream responsible for spatial features and the other one for that of temporal ones in each video. A raw frame (the first one) is fed to the spatial CNN and on the other side the optical flow of all video frames is fed to the second network to identify the right action. Appart from architecture, another difference is that the CNN's used don't have to be pre-trained so that a language can be developed by tabula rasa agents (similar to Choi's work). The second agent architecture is as follows:\n",
    "\n",
    "<center><img src=\"fig_4.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the agents by backpropagating the error through them (only as a listener) at the end of each round. We expect the agents to learn similar sequences of symbols for each organism type and their actions by the end of training. By evaluating the results we would \n",
    "like to answer the following questions:\n",
    "- Where in the sentences the actions are encoded?\n",
    "- How are they ordered? Action-type? Type-action? Or in a different order?\n",
    "- Is there any specific relationship between different organism types and actions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Experimental Setup:__\n",
    "#### __Two-Stream Agents:__\n",
    "Let's import the agents and the modules needed. Also, we can initialize a random seed to get persistnt results in each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from train import train_round\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from agents import TSAgent\n",
    "import obverter\n",
    "from data import OrganismsDataset\n",
    "from utils import *\n",
    "\n",
    "seed = 365\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# run it on GPU if cuda available (recommended)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# number of games played in each round (mini-batch size)\n",
    "batch_size = 24\n",
    "\n",
    "# number of symbols (words) available to each agent to use\n",
    "vocab_size = 5\n",
    "\n",
    "# length of maximum sentence they can compose\n",
    "max_sen_len = 10\n",
    "\n",
    "# number of epochs/rounds\n",
    "rounds = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build two two-stream agents to play with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the agents\n",
    "agent_a = TSAgent(vocab_size=vocab_size).to(device)\n",
    "agent_b = TSAgent(vocab_size=vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we instantiate the loss function and the optimizers for each agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative log liklihood loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# optimizers\n",
    "optimizer_a_gen = optim.Adam([p for p in agent_a.parameters() if p.requires_grad], lr=6e-4)\n",
    "optimizer_b_gen = optim.Adam([p for p in agent_b.parameters() if p.requires_grad], lr=6e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a dataloader for loading the pictures in pairs with ther corresponding labels (1 as similar and 0 as dissimilar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = OrganismsDataset(path='./organisms/', return_pair=True, n_pairs=1000)\n",
    "testing_set = OrganismsDataset('./organisms/test/', return_pair=True, n_pairs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can start a game of 2000 rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent1_accuracy_history = []\n",
    "agent1_message_length_history = []\n",
    "agent1_loss_history = []\n",
    "\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "for round in tqdm(range(rounds)):\n",
    "    print(\"********** round %d **********\" % round)\n",
    "    round_accuracy, round_loss, round_sentence_length = train_round(agent_a, agent_b, optimizer_b_gen, max_sen_len, vocab_size)\n",
    "    print_round_stats(round_accuracy, round_loss, round_sentence_length)\n",
    "\n",
    "    agent1_accuracy_history.append(round_accuracy)\n",
    "    agent1_message_length_history.append(round_sentence_length / 10)\n",
    "    agent1_loss_history.append(round_loss)\n",
    "\n",
    "    round += 1\n",
    "    print(\"replacing roles\")\n",
    "    print(\"********** round %d **********\" % round)\n",
    "\n",
    "    round_accuracy, round_loss, round_sentence_length = train_round(agent_b, agent_a, optimizer_a_gen, max_sen_len, vocab_size)\n",
    "    print_round_stats(round_accuracy, round_loss, round_sentence_length)\n",
    "\n",
    "    t = list(range(len(agent1_accuracy_history)))\n",
    "    plt.plot(t, agent1_accuracy_history, label=\"Accuracy\")\n",
    "    plt.plot(t, agent1_message_length_history, label=\"Message length (/10)\")\n",
    "    plt.plot(t, agent1_loss_history, label=\"Training loss\")\n",
    "\n",
    "    plt.xlabel('# Rounds')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"graph.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    if round % 50 == 0:\n",
    "        torch.save(agent_a.state_dict(), os.path.join('checkpoints', 'agent1-%d.ckp' % round))\n",
    "        torch.save(agent_b.state_dict(), os.path.join('checkpoints', 'agent2-%d.ckp' % round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"two_stream_training_results.png\"></center>\n",
    "\n",
    "As you can see in the graph above, the players came to an agreement (converged) after around 200 rounds. Let's see what do  they call the samples from our test data which they never faced before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent A sentence ===> a--------- ++ poi spi ++ a--------- <=== Agent B sentence\n",
      "Agent A sentence ===> edcddededd ++ edi spi ++ ebbbbbbbbb <=== Agent B sentence\n",
      "Agent A sentence ===> a--------- ++ poi spi ++ a--------- <=== Agent B sentence\n",
      "Agent A sentence ===> cbcccccccc ++ poi sti ++ bccccccccc <=== Agent B sentence\n",
      "Agent A sentence ===> cdccaccccc ++ poi sti ++ cbcccccccc <=== Agent B sentence\n",
      "Agent A sentence ===> cdcacccacc ++ poi sti ++ dccccccccc <=== Agent B sentence\n",
      "Agent A sentence ===> ccaaaeeeee ++ poi sti ++ cdcccccccc <=== Agent B sentence\n",
      "Agent A sentence ===> eeeeeeedee ++ edi spi ++ eeaddddddd <=== Agent B sentence\n",
      "Agent A sentence ===> cddeeeeeed ++ edi mov ++ dddbdbbdbd <=== Agent B sentence\n",
      "Agent A sentence ===> aa-------- ++ poi spi ++ a--------- <=== Agent B sentence\n",
      "Agent A sentence ===> dddedededd ++ edi mov ++ dddbbbbbbd <=== Agent B sentence\n",
      "Agent A sentence ===> ecaacaaaca ++ poi mov ++ eccccccccc <=== Agent B sentence\n",
      "Agent A sentence ===> beeebecaeb ++ poi mov ++ bcaccccccc <=== Agent B sentence\n",
      "Agent A sentence ===> cbeeebebbe ++ edi mov ++ dcdcbccccc <=== Agent B sentence\n",
      "Agent A sentence ===> cdcaccccac ++ poi sti ++ bccccccccc <=== Agent B sentence\n",
      "Agent A sentence ===> ccebbeeeee ++ poi sti ++ cdcccccccc <=== Agent B sentence\n",
      "Agent A sentence ===> eddddedede ++ edi spi ++ edbdbdbbdb <=== Agent B sentence\n",
      "Agent A sentence ===> eeeeeeeeee ++ edi spi ++ eaeddddddd <=== Agent B sentence\n",
      "Agent A sentence ===> a--------- ++ poi spi ++ a--------- <=== Agent B sentence\n",
      "Agent A sentence ===> eaeeeaeeee ++ edi spi ++ eedadddddd <=== Agent B sentence\n",
      "Agent A sentence ===> deecaeecae ++ poi mov ++ eccccccccc <=== Agent B sentence\n",
      "Agent A sentence ===> a--------- ++ poi spi ++ a--------- <=== Agent B sentence\n",
      "Agent A sentence ===> beceeecebe ++ edi mov ++ ecddbbbcdd <=== Agent B sentence\n",
      "Agent A sentence ===> edddddddbb ++ edi spi ++ ebbbbbbbbb <=== Agent B sentence\n",
      "Agent A sentence ===> eccccccccc ++ poi mov ++ eccccccccc <=== Agent B sentence\n",
      "Agent A sentence ===> cbbebabadb ++ edi mov ++ ddddbbbbdb <=== Agent B sentence\n",
      "Agent A sentence ===> ccebbeeeee ++ edi sti ++ cdcddddddd <=== Agent B sentence\n",
      "Agent A sentence ===> deceededed ++ edi mov ++ ddcccccccc <=== Agent B sentence\n",
      "Agent A sentence ===> beaeeddedd ++ edi spi ++ eebdbbdbbd <=== Agent B sentence\n",
      "Agent A sentence ===> a--------- ++ poi spi ++ a--------- <=== Agent B sentence\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(testing_set, 30, drop_last=True)\n",
    "\n",
    "def evaluate(agent_a, agent_b, round_):\n",
    "    data_test_iter = iter(test_loader)\n",
    "\n",
    "    org, _, _ = next(data_test_iter)\n",
    "    agent_a.load_state_dict(torch.load(fr'checkpoints/agent1-{round_}.ckp'))\n",
    "    agent_b.load_state_dict(torch.load(fr'checkpoints/agent2-{round_}.ckp'))\n",
    "\n",
    "    agent_a.eval()\n",
    "    agent_b.eval()\n",
    "    \n",
    "    frame_zero = org[0].float().to(device)\n",
    "    motion_frame = org[1].float().to(device)\n",
    "    \n",
    "    acts_a, probs_a = obverter.decode(agent_a, frame_zero, motion_frame, max_sen_len, vocab_size, device)\n",
    "    acts_b, probs_b = obverter.decode(agent_b, frame_zero, motion_frame, max_sen_len, vocab_size, device)\n",
    "    \n",
    "    \n",
    "    for i in range(acts_a.size(0)):\n",
    "        sentence_a = get_message(acts_a[i], vocab_size)\n",
    "        sentence_b = get_message(acts_b[i], vocab_size)\n",
    "        \n",
    "        a_pad = '-' * (max_sen_len-len(sentence_a))\n",
    "        b_pad = '-' * (max_sen_len-len(sentence_b))\n",
    "        \n",
    "        print(f'Agent A sentence ===> {sentence_a}{a_pad} ++ {org[2][i][:3]} {org[3][i][:3]} ++ {sentence_b}{b_pad} <=== Agent B sentence')\n",
    "        \n",
    "\n",
    "evaluate(agent_a, agent_b, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentences you see above are from the agents after 150 rounds in which they already started both converging and also reducing the number of words in the sentences. The  main issue is the accuracy of the words which show more games need to be played. Below we evaluate the agents after convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent A sentence ===> a--------- ++ poi spi ++ a--------- <=== Agent B sentence\n",
      "Agent A sentence ===> e--------- ++ edi spi ++ e--------- <=== Agent B sentence\n",
      "Agent A sentence ===> a--------- ++ poi spi ++ a--------- <=== Agent B sentence\n",
      "Agent A sentence ===> c--------- ++ poi sti ++ c--------- <=== Agent B sentence\n",
      "Agent A sentence ===> c--------- ++ poi sti ++ c--------- <=== Agent B sentence\n",
      "Agent A sentence ===> c--------- ++ poi sti ++ c--------- <=== Agent B sentence\n",
      "Agent A sentence ===> c--------- ++ poi sti ++ cda------- <=== Agent B sentence\n",
      "Agent A sentence ===> ea-------- ++ edi spi ++ ea-------- <=== Agent B sentence\n",
      "Agent A sentence ===> d--------- ++ edi mov ++ d--------- <=== Agent B sentence\n",
      "Agent A sentence ===> a--------- ++ poi spi ++ a--------- <=== Agent B sentence\n",
      "Agent A sentence ===> d--------- ++ edi mov ++ ee-------- <=== Agent B sentence\n",
      "Agent A sentence ===> b--------- ++ poi mov ++ b--------- <=== Agent B sentence\n",
      "Agent A sentence ===> b--------- ++ poi mov ++ b--------- <=== Agent B sentence\n",
      "Agent A sentence ===> d--------- ++ edi mov ++ d--------- <=== Agent B sentence\n",
      "Agent A sentence ===> c--------- ++ poi sti ++ c--------- <=== Agent B sentence\n",
      "Agent A sentence ===> cd-------- ++ poi sti ++ c--------- <=== Agent B sentence\n",
      "Agent A sentence ===> e--------- ++ edi spi ++ e--------- <=== Agent B sentence\n",
      "Agent A sentence ===> e--------- ++ edi spi ++ ed-------- <=== Agent B sentence\n",
      "Agent A sentence ===> a--------- ++ poi spi ++ a--------- <=== Agent B sentence\n",
      "Agent A sentence ===> e--------- ++ edi spi ++ e--------- <=== Agent B sentence\n",
      "Agent A sentence ===> da-------- ++ poi mov ++ bbebbebebe <=== Agent B sentence\n",
      "Agent A sentence ===> a--------- ++ poi spi ++ a--------- <=== Agent B sentence\n",
      "Agent A sentence ===> d--------- ++ edi mov ++ beeeeeeeee <=== Agent B sentence\n",
      "Agent A sentence ===> e--------- ++ edi spi ++ e--------- <=== Agent B sentence\n",
      "Agent A sentence ===> b--------- ++ poi mov ++ b--------- <=== Agent B sentence\n",
      "Agent A sentence ===> d--------- ++ edi mov ++ d--------- <=== Agent B sentence\n",
      "Agent A sentence ===> ce-------- ++ edi sti ++ cd-------- <=== Agent B sentence\n",
      "Agent A sentence ===> d--------- ++ edi mov ++ d--------- <=== Agent B sentence\n",
      "Agent A sentence ===> e--------- ++ edi spi ++ e--------- <=== Agent B sentence\n",
      "Agent A sentence ===> a--------- ++ poi spi ++ a--------- <=== Agent B sentence\n"
     ]
    }
   ],
   "source": [
    "evaluate(agent_a, agent_b, 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
